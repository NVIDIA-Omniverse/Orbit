{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used device: cuda\n"
     ]
    }
   ],
   "source": [
    "import imageio as io\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import tqdm\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "\n",
    "from transformers import OwlViTProcessor, OwlViTForObjectDetection\n",
    "from segment_anything import SamPredictor, sam_model_registry, SamAutomaticMaskGenerator\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Used device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PoseApproximator:\n",
    "    def __init__(self, device):\n",
    "\n",
    "        self.device = device\n",
    "\n",
    "        self.od_processor = OwlViTProcessor.from_pretrained(\"google/owlvit-base-patch32\")\n",
    "        self.od_model = OwlViTForObjectDetection.from_pretrained(\"google/owlvit-base-patch32\").to(self.device)\n",
    "\n",
    "        SAM_MODEL_TYPE = \"vit_h\" #vit_l, vit_b\n",
    "        SAM_CHECKPOINT = \"sam_checkpoint/sam_vit_h_4b8939.pth\"\n",
    "        self.segm_model = SamPredictor(sam_model_registry[SAM_MODEL_TYPE](checkpoint=SAM_CHECKPOINT))\n",
    "\n",
    "    def __call__(self, image, query_image, depth, od_score_thresh=0.1):\n",
    "        od_inputs = self.od_processor(images=image, query_images=query_image, return_tensors=\"pt\",).to(DEVICE)\n",
    "        with torch.no_grad():\n",
    "            # (1) OD\n",
    "            od_outputs = self.od_model.image_guided_detection(**od_inputs)\n",
    "            od_logits = torch.max(od_outputs[\"logits\"][0], dim=-1)\n",
    "\n",
    "            od_scores = torch.sigmoid(od_logits.values).cpu().detach().numpy()\n",
    "            od_labels = od_logits.indices.cpu().detach().numpy()\n",
    "            od_bboxes = od_outputs[\"target_pred_boxes\"][0].cpu().detach().numpy()\n",
    "\n",
    "            #TODO: filter based on score thresh\n",
    "            # box: A length 4 array given a box prompt to the model, in XYXY format.\n",
    "\n",
    "            best_bbox: np.ndarray = None\n",
    "\n",
    "            # (2) Segmentation\n",
    "            input_label = np.array([1])\n",
    "            self.segm_model.set_image(image)\n",
    "            segm_masks, segm_scores, segm_logits = self.segm_model.predict(\n",
    "                box=best_bbox,\n",
    "                point_labels=input_label,\n",
    "                multimask_output=True,\n",
    "            )\n",
    "            max_idx = np.argmax(segm_scores)\n",
    "            segm_masks = segm_masks[max_idx:max_idx + 1, ...]\n",
    "            segm_scores = segm_scores[max_idx:max_idx + 1]\n",
    "\n",
    "            # (3) Estimate 3D position (world) using the depth\n",
    "            # (segment out the depth -> depth point estimate -> deproject bbox/centroid from 2D img space to 3D world Euclidean space -> (Xw, Yw, Zw))\n",
    "\n",
    "            # (4) Tracker (track pose temporaly)\n",
    "\n",
    "        return (od_scores, od_labels, od_bboxes), (segm_scores, segm_masks)\n",
    "\n",
    "    def plot_boxes(self, img, scores, boxes):\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(8, 8))\n",
    "        ax.imshow(img, extent=(0, 1, 1, 0))\n",
    "        ax.set_axis_off()\n",
    "\n",
    "        for score, box in zip(scores, boxes):\n",
    "            cx, cy, w, h = box\n",
    "            ax.plot(\n",
    "                [cx-w/2, cx+w/2, cx+w/2, cx-w/2, cx-w/2],\n",
    "                [cy-h/2, cy-h/2, cy+h/2, cy+h/2, cy-h/2], \n",
    "                \"r\"\n",
    "            )\n",
    "\n",
    "            ax.text(\n",
    "                cx - w / 2,\n",
    "                cy + h / 2 + 0.015,\n",
    "                f\"{score:1.2f}\",\n",
    "                ha=\"left\",\n",
    "                va=\"top\",\n",
    "                color=\"red\",\n",
    "                bbox={\n",
    "                    \"facecolor\": \"white\",\n",
    "                    \"edgecolor\": \"red\",\n",
    "                    \"boxstyle\": \"square,pad=.3\"\n",
    "                }\n",
    "            )\n",
    "        plt.show()\n",
    "        plt.clf()\n",
    "\n",
    "    def plot_masks(self, img, scores, masks):\n",
    "        def show_mask(mask, ax, random_color=False):\n",
    "            if random_color:\n",
    "                color = np.concatenate([np.random.random(3), np.array([0.6])], axis=0)\n",
    "            else:\n",
    "                color = np.array([255, 0, 0, 0.6])\n",
    "                color[:-1] /= 255\n",
    "            h, w = mask.shape[-2:]\n",
    "            mask_image = mask.reshape(h, w, 1) * color.reshape(1, 1, -1)\n",
    "            ax.imshow(mask_image)\n",
    "\n",
    "        plt.figure(figsize=(10,10))\n",
    "\n",
    "        for i, (mask, score) in enumerate(zip(masks, scores)):\n",
    "            plt.imshow(img)\n",
    "            show_mask(mask, plt.gca())\n",
    "        \n",
    "        plt.title(f\"Mask {i+1}, Score: {score:.3f}\", fontsize=18)\n",
    "        plt.axis('off')    \n",
    "        plt.show()\n",
    "        plt.clf()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "state_approx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
